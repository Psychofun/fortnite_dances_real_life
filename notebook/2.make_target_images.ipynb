{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take a video on webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd ../src/utils\n",
    "python save_img.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Frames from Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "save_dir = Path('../data/target/')\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "img_dir = save_dir.joinpath('images')\n",
    "img_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(str(save_dir.joinpath('filen_name.mp4')))\n",
    "i = 0\n",
    "j = 0\n",
    "flag = None\n",
    "while(cap.isOpened()):\n",
    "    #Extract only 1 of 2 images\n",
    "    flag, frame = cap.read()\n",
    "    if flag == False:\n",
    "        break\n",
    "    if j%2 == 0:\n",
    "        \n",
    "        #print(frame.shape)\n",
    "        #frame = np.swapaxes(frame,0,1)\n",
    "        frame = frame[355:-10,645:-645,:]\n",
    "        #frame = cv2.resize(frame, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        #print(frame.shape)\n",
    "        #print(\"type of frame\", type(frame))\n",
    "\n",
    "        #if i >= 10:\n",
    "        #    break\n",
    "        \n",
    "        cv2.imwrite(str(img_dir.joinpath(f'img_{i:05d}.png')), frame)\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    j+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose estimation (OpenPose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openpose_dir = Path('../src/pytorch_Realtime_Multi-Person_Pose_Estimation/')\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(openpose_dir))\n",
    "sys.path.append('../src/utils')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openpose\n",
    "from network.rtpose_vgg import get_model\n",
    "from evaluate.coco_eval import get_multiplier, get_outputs\n",
    "\n",
    "# utils\n",
    "from openpose_utils import remove_noise, get_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_name = openpose_dir.joinpath('network/weight/pose_model.pth')\n",
    "\n",
    "model = get_model('vgg19')     \n",
    "model.load_state_dict(torch.load(weight_name))\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "model.float()\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('../data/target/')\n",
    "#save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "img_dir = save_dir.joinpath('images')\n",
    "#img_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_path = sorted(img_dir.iterdir())[0]\n",
    "img = cv2.imread(str(img_path))\n",
    "shape_dst = np.min(img.shape[:2])\n",
    "# offset\n",
    "oh = (img.shape[0] - shape_dst) // 2\n",
    "ow = (img.shape[1] - shape_dst) // 2\n",
    "\n",
    "img = img[oh:oh+shape_dst, ow:ow+shape_dst]\n",
    "img = cv2.resize(img, (512, 512))\n",
    "          \n",
    "plt.imshow(img[:,:,[2, 1, 0]]) # BGR -> RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier = get_multiplier(img)\n",
    "with torch.no_grad():\n",
    "    paf, heatmap = get_outputs(multiplier, img, model, 'rtpose')\n",
    "    \n",
    "r_heatmap = np.array([remove_noise(ht)\n",
    "                      for ht in heatmap.transpose(2, 0, 1)[:-1]])\\\n",
    "                     .transpose(1, 2, 0)\n",
    "heatmap[:, :, :-1] = r_heatmap\n",
    "param = {'thre1': 0.1, 'thre2': 0.05, 'thre3': 0.5}\n",
    "label = get_pose(param, heatmap, paf)\n",
    "\n",
    "plt.imshow(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make label images for pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = save_dir.joinpath('train')\n",
    "train_dir.mkdir(exist_ok=True)\n",
    "\n",
    "train_img_dir = train_dir.joinpath('train_img')\n",
    "train_img_dir.mkdir(exist_ok=True)\n",
    "train_label_dir = train_dir.joinpath('train_label')\n",
    "train_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for idx in tqdm(range(3177,7729)):\n",
    "    img_path = img_dir.joinpath(f'img_{idx:05d}.png')\n",
    "    img = cv2.imread(str(img_path))\n",
    "    shape_dst = np.min(img.shape[:2])\n",
    "    oh = (img.shape[0] - shape_dst) // 2\n",
    "    ow = (img.shape[1] - shape_dst) // 2\n",
    "\n",
    "    img = img[oh:oh+shape_dst, ow:ow+shape_dst]\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    multiplier = get_multiplier(img)\n",
    "    with torch.no_grad():\n",
    "        paf, heatmap = get_outputs(multiplier, img, model, 'rtpose')\n",
    "    r_heatmap = np.array([remove_noise(ht)\n",
    "                      for ht in heatmap.transpose(2, 0, 1)[:-1]])\\\n",
    "                     .transpose(1, 2, 0)\n",
    "    heatmap[:, :, :-1] = r_heatmap\n",
    "    param = {'thre1': 0.1, 'thre2': 0.05, 'thre3': 0.5}\n",
    "    label = get_pose(param, heatmap, paf)\n",
    "    \n",
    "    cv2.imwrite(str(train_img_dir.joinpath(f'img_{idx:05d}.png')), img)    \n",
    "    cv2.imwrite(str(train_label_dir.joinpath(f'label_{idx:05d}.png')), label)\n",
    "    \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privateai",
   "language": "python",
   "name": "privateai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
